{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“© SMS Spam Classifier with TensorFlow\n",
        "\n",
        "This project builds a machine learning model that classifies SMS messages as either **\"ham\" (not spam)** or **\"spam\"** using TensorFlow and natural language processing.\n",
        "\n",
        "You'll walk through the entire ML workflow, including:\n",
        "\n",
        "- ðŸ“¥ Loading and preparing real-world SMS data  \n",
        "- ðŸ§¼ Preprocessing text with a `TextVectorization` layer  \n",
        "- ðŸ§  Building and training a neural network for binary classification  \n",
        "- ðŸ“ˆ Evaluating model accuracy with confusion matrix, ROC curve, and prediction confidence plots  \n",
        "- ðŸŒ€ Visualizing message patterns with word clouds, t-SNE, and misclassification analysis\n",
        "\n",
        "The final result is a function that can predict whether a given message is spam, including the modelâ€™s confidence score.\n",
        "\n",
        "> â€œCongratulations! You've won a free iPhone!â€ â€” spam  \n",
        "> â€œAre we still on for dinner?â€ â€” ham\n",
        "\n",
        "Letâ€™s classify some texts! ðŸš€\n"
      ],
      "metadata": {
        "id": "wjAYWhTNO3Hy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RZOuS9LWQvv",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  !pip install tf-nightly\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "!pip install tensorflow-datasets\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHwYXHXCar3",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "!ls -l /content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/sample_data"
      ],
      "metadata": {
        "id": "DyP2sHgD8iwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['label', 'message']\n",
        "train_data_df = pd.read_csv(train_file_path, sep='\\t', header=None, names=column_names)\n",
        "test_data_df = pd.read_csv(test_file_path, sep='\\t', header=None, names=column_names)\n",
        "\n",
        "print(train_data_df.head())\n",
        "print(train_data_df.tail())\n",
        "print(len(train_data_df))\n",
        "print(test_data_df.head())\n",
        "print(len(test_data_df))"
      ],
      "metadata": {
        "id": "uUKV8oKy8RE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualizations\n",
        "\n",
        "### Histograms"
      ],
      "metadata": {
        "id": "kf7nyXwgJoLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Visualize label counts\n",
        "sns.countplot(x='label', data=train_data_df)\n",
        "plt.title('Label Distribution in Training Data')\n",
        "plt.xlabel('Label (ham/spam)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y6tRmPMkJQBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Message Length Distribution\n",
        "\n",
        "# Add a 'length' column to training data\n",
        "train_data_df['length'] = train_data_df['message'].apply(len)\n",
        "\n",
        "# Plot message length distribution\n",
        "plt.hist(train_data_df['length'], bins=40, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribution of Message Lengths')\n",
        "plt.xlabel('Message Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tdhQtwOnJVQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Boxplot"
      ],
      "metadata": {
        "id": "Aa-ma-peJ7VG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Boxplot comparing message lengths between ham and spam\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='label', y='length', data=train_data_df, palette={'ham':'green', 'spam':'red'})\n",
        "\n",
        "plt.title('Message Lengths by Label', fontsize=14)\n",
        "plt.xlabel('Message Type', fontsize=12)\n",
        "plt.ylabel('Number of Characters in Message', fontsize=12)\n",
        "\n",
        "plt.text(-0.3, train_data_df['length'].max() * 0.95, \"ðŸ‘ˆ Ham messages are usually shorter\", color='green')\n",
        "plt.text(0.7, train_data_df['length'].max() * 0.95, \"Spam messages often longer ðŸ‘‰\", color='red')\n",
        "\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jf-Qq4zVJgr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Clouds"
      ],
      "metadata": {
        "id": "v4cyMgKIKajB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Combine all spam and ham text separately\n",
        "spam_text = ' '.join(train_data_df[train_data_df['label'] == 'spam']['message'])\n",
        "ham_text = ' '.join(train_data_df[train_data_df['label'] == 'ham']['message'])\n",
        "\n",
        "# Generate word clouds with custom color maps\n",
        "spam_wc = WordCloud(\n",
        "    width=600,\n",
        "    height=400,\n",
        "    background_color='white',\n",
        "    colormap='hot'  # ðŸ”¥ red/yellow tones for angry spam\n",
        ").generate(spam_text)\n",
        "\n",
        "ham_wc = WordCloud(\n",
        "    width=600,\n",
        "    height=400,\n",
        "    background_color='white',\n",
        "    colormap='Greens'  # ðŸŒ¿ calm and friendly ham\n",
        ").generate(ham_text)\n",
        "\n",
        "# Show them side by side\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(ham_wc, interpolation='bilinear')\n",
        "plt.title(\"Common Words in Ham\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(spam_wc, interpolation='bilinear')\n",
        "plt.title(\"Common Words in Spam\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "g2lQG-9OKEkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "\n",
        "# 1. Prepare your TextVectorization layer\n",
        "vectorizer = keras.layers.TextVectorization(\n",
        "    max_tokens=10000,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=100\n",
        ")\n",
        "\n",
        "# 2. Get train and test text\n",
        "train_texts = train_data_df['message'].values\n",
        "test_texts = test_data_df['message'].values\n",
        "\n",
        "# 3. Adapt the vectorizer to training texts\n",
        "vectorizer.adapt(train_texts)\n",
        "\n",
        "# 4. Build the model\n",
        "model = keras.Sequential()\n",
        "model.add(vectorizer)\n",
        "model.add(keras.layers.Embedding(input_dim=10000, output_dim=16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid')) # sigmoid = output is probability\n",
        "\n",
        "# 5. Compile the model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 6. Convert labels from strings to integers\n",
        "train_labels = train_data_df['label'].map({'ham': 0, 'spam': 1}).values\n",
        "test_labels = test_data_df['label'].map({'ham': 0, 'spam': 1}).values\n",
        "\n",
        "# 7. Fit the model\n",
        "model.fit(train_texts, train_labels, epochs=12, validation_data=(test_texts, test_labels))"
      ],
      "metadata": {
        "id": "2UchotRW_dc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Prediction Confidence Distribution"
      ],
      "metadata": {
        "id": "R4wV3wHGK1Ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set\n",
        "pred_probs = model.predict(tf.constant(test_texts)).flatten()\n",
        "true_labels = test_labels\n",
        "\n",
        "# Plot histogram of prediction confidence\n",
        "plt.hist(pred_probs[true_labels == 0], bins=30, alpha=0.7, label='ham', color='green')\n",
        "plt.hist(pred_probs[true_labels == 1], bins=30, alpha=0.7, label='spam', color='red')\n",
        "plt.title('Model Prediction Confidence')\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OFDbHjaJKz0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix Heatmap"
      ],
      "metadata": {
        "id": "DFAaQYhANzfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "pred_classes = (pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_classes)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['ham', 'spam'], yticklabels=['ham', 'spam'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kUZox0vPNxs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "outputs": [],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "\n",
        "  # Convert to Tensor (batch of 1 string)\n",
        "  pred_tensor = tf.constant([pred_text])\n",
        "\n",
        "  prediction = model.predict(pred_tensor)[0][0]\n",
        "\n",
        "  label = 'spam' if prediction > 0.5 else 'ham'\n",
        "\n",
        "  return [prediction, label]\n",
        "\n",
        "pred_text = \"how are you doing today?\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Receiver Operating Characteristic (ROC) Curve"
      ],
      "metadata": {
        "id": "dF6eDgWzOB4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(true_labels, pred_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # baseline\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate (Recall)')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UTU-NbUcOHdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Waterfall Plot of Individual Predictions (Top Confident vs Misclassifications)"
      ],
      "metadata": {
        "id": "S9AkAUwgOXPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and collect useful info\n",
        "import pandas as pd\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'text': test_texts,\n",
        "    'true_label': test_labels,\n",
        "    'pred_prob': pred_probs,\n",
        "    'pred_class': (pred_probs > 0.5).astype(int)\n",
        "})\n",
        "\n",
        "# Add info columns\n",
        "results_df['correct'] = results_df['true_label'] == results_df['pred_class']\n",
        "results_df['confidence'] = np.abs(results_df['pred_prob'] - 0.5) * 2  # how far from 0.5\n",
        "\n",
        "# Sort by confidence\n",
        "results_df = results_df.sort_values('confidence', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "colors = results_df['correct'].map({True: 'green', False: 'red'})\n",
        "plt.bar(range(len(results_df)), results_df['confidence'], color=colors)\n",
        "plt.title('Prediction Confidence per Message (Green = Correct, Red = Incorrect)')\n",
        "plt.xlabel('Message Index (sorted by confidence)')\n",
        "plt.ylabel('Confidence Score')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "m3ndE9qBOaQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxotov85SjsC"
      },
      "outputs": [],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won Â£1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "fcc_sms_text_classification.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
